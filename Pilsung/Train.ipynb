{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from utils.CLR import*\n",
    "from utils.LoadData import load_CW_Source\n",
    "from Model.CNN import cnn_classifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def train_model(X_profiling, Y_profiling, X_test, Y_test, model, save_file_name, epochs=150, batch_size=100,\n",
    "                max_lr=1e-3):\n",
    "\n",
    "    # Save model every epoch\n",
    "    save_model = ModelCheckpoint(\n",
    "                    filepath=save_file_name,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    save_best_only=True)\n",
    "\n",
    "    # Get the input layer shape\n",
    "    input_layer_shape = model.get_layer(index=0).input_shape[0]\n",
    "\n",
    "    # Sanity check\n",
    "    if input_layer_shape[1] != len(X_profiling[0]):\n",
    "        print(\"Error: model input shape %d instead of %d is not expected ...\" % (\n",
    "        input_layer_shape[1], len(X_profiling[0])))\n",
    "        sys.exit(-1)\n",
    "    Reshaped_X_profiling, Reshaped_X_test = X_profiling.reshape(\n",
    "        (X_profiling.shape[0], X_profiling.shape[1], 1)), X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # One Cycle Policy\n",
    "    lr_manager = OneCycleLR(max_lr=max_lr, end_percentage=0.2, scale_percentage=0.1, maximum_momentum=None,\n",
    "                            minimum_momentum=None, verbose=True)\n",
    "\n",
    "    callbacks = [save_model, lr_manager]\n",
    "\n",
    "    history = model.fit(x=Reshaped_X_profiling, y=to_categorical(Y_profiling, num_classes=256),\n",
    "                        validation_data=(Reshaped_X_test, to_categorical(Y_test, num_classes=256)),\n",
    "                        batch_size=batch_size, verbose=1, epochs=epochs, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 600, 1)]          0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 600, 4)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 600, 4)            16        \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 300, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 16)                19216     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               4352      \n",
      "=================================================================\n",
      "Total params: 23,864\n",
      "Trainable params: 23,856\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "\n",
      "############### Starting Training #################\n",
      "\n",
      "Epoch 1/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 5.5879 - accuracy: 0.0042 - lr: 0.00061 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 5.5875 - accuracy: 0.0043 - val_loss: 5.6156 - val_accuracy: 0.0050\n",
      "Epoch 2/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 5.4621 - accuracy: 0.0081 - lr: 0.00072 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.4592 - accuracy: 0.0082 - val_loss: 5.5641 - val_accuracy: 0.0050\n",
      "Epoch 3/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 5.1935 - accuracy: 0.0231 - lr: 0.00083 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.1867 - accuracy: 0.0231 - val_loss: 5.2884 - val_accuracy: 0.0145\n",
      "Epoch 4/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 4.7046 - accuracy: 0.0474 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 4.6962 - accuracy: 0.0473 - val_loss: 4.7699 - val_accuracy: 0.0440\n",
      "Epoch 5/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 4.0955 - accuracy: 0.0949 - lr: 0.00106 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 4.0724 - accuracy: 0.0983 - val_loss: 4.1131 - val_accuracy: 0.1090\n",
      "Epoch 6/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 3.3026 - accuracy: 0.2218 - lr: 0.00117 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 3.2887 - accuracy: 0.2244 - val_loss: 3.3761 - val_accuracy: 0.1780\n",
      "Epoch 7/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 2.4808 - accuracy: 0.3738 - lr: 0.00128 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 2.4798 - accuracy: 0.3739 - val_loss: 2.7038 - val_accuracy: 0.2740\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.8260 - accuracy: 0.5156 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.8260 - accuracy: 0.5156 - val_loss: 2.3263 - val_accuracy: 0.3360\n",
      "Epoch 9/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 1.3652 - accuracy: 0.6191 - lr: 0.00151 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.3590 - accuracy: 0.6207 - val_loss: 2.1289 - val_accuracy: 0.3815\n",
      "Epoch 10/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.0555 - accuracy: 0.6961 - lr: 0.00162 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.0552 - accuracy: 0.6962 - val_loss: 1.9451 - val_accuracy: 0.4110\n",
      "Epoch 11/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.8555 - accuracy: 0.7461 - lr: 0.00173 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.8542 - accuracy: 0.7467 - val_loss: 1.5556 - val_accuracy: 0.5275\n",
      "Epoch 12/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.7846 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7099 - accuracy: 0.7846 - val_loss: 1.3253 - val_accuracy: 0.5885\n",
      "Epoch 13/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.6314 - accuracy: 0.8023 - lr: 0.00196 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6298 - accuracy: 0.8026 - val_loss: 1.1189 - val_accuracy: 0.6475\n",
      "Epoch 14/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5561 - accuracy: 0.8238 - lr: 0.00207 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5555 - accuracy: 0.8241 - val_loss: 1.0657 - val_accuracy: 0.6725\n",
      "Epoch 15/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.5002 - accuracy: 0.8394 - lr: 0.00218 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4988 - accuracy: 0.8396 - val_loss: 1.0594 - val_accuracy: 0.6755\n",
      "Epoch 16/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.4769 - accuracy: 0.8452 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4757 - accuracy: 0.8457 - val_loss: 0.8841 - val_accuracy: 0.7285\n",
      "Epoch 17/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8537 - lr: 0.00241 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4410 - accuracy: 0.8535 - val_loss: 0.6867 - val_accuracy: 0.7815\n",
      "Epoch 18/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.8643 - lr: 0.00252 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4104 - accuracy: 0.8646 - val_loss: 0.6056 - val_accuracy: 0.8070\n",
      "Epoch 19/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3817 - accuracy: 0.8710 - lr: 0.00263 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3821 - accuracy: 0.8711 - val_loss: 0.6373 - val_accuracy: 0.7935\n",
      "Epoch 20/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3724 - accuracy: 0.8748 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3721 - accuracy: 0.8746 - val_loss: 0.7354 - val_accuracy: 0.7605\n",
      "Epoch 21/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3530 - accuracy: 0.8780 - lr: 0.00286 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3538 - accuracy: 0.8778 - val_loss: 0.8508 - val_accuracy: 0.7330\n",
      "Epoch 22/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3489 - accuracy: 0.8794 - lr: 0.00297 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3494 - accuracy: 0.8796 - val_loss: 0.5854 - val_accuracy: 0.8115\n",
      "Epoch 23/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3434 - accuracy: 0.8826 - lr: 0.00308 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3433 - accuracy: 0.8828 - val_loss: 0.5376 - val_accuracy: 0.8270\n",
      "Epoch 24/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.8866 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3273 - accuracy: 0.8866 - val_loss: 0.5463 - val_accuracy: 0.8280\n",
      "Epoch 25/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.8893 - lr: 0.00331 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3176 - accuracy: 0.8894 - val_loss: 0.5171 - val_accuracy: 0.8280\n",
      "Epoch 26/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3180 - accuracy: 0.8896 - lr: 0.00342 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3180 - accuracy: 0.8898 - val_loss: 0.5964 - val_accuracy: 0.8150\n",
      "Epoch 27/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.3105 - accuracy: 0.8927 - lr: 0.00353 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3081 - accuracy: 0.8930 - val_loss: 0.5152 - val_accuracy: 0.8340\n",
      "Epoch 28/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3093 - accuracy: 0.8898 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3098 - accuracy: 0.8894 - val_loss: 0.4767 - val_accuracy: 0.8510\n",
      "Epoch 29/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8937 - lr: 0.00376 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3040 - accuracy: 0.8941 - val_loss: 0.4710 - val_accuracy: 0.8490\n",
      "Epoch 30/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2816 - accuracy: 0.8996 - lr: 0.00387 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2819 - accuracy: 0.9003 - val_loss: 0.5362 - val_accuracy: 0.8355\n",
      "Epoch 31/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2708 - accuracy: 0.9046 - lr: 0.00398 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2700 - accuracy: 0.9045 - val_loss: 0.4467 - val_accuracy: 0.8580\n",
      "Epoch 32/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2785 - accuracy: 0.9009 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2762 - accuracy: 0.9016 - val_loss: 0.4447 - val_accuracy: 0.8625\n",
      "Epoch 33/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2695 - accuracy: 0.9054 - lr: 0.00421 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2721 - accuracy: 0.9048 - val_loss: 0.4367 - val_accuracy: 0.8595\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.8995 - lr: 0.00432 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2800 - accuracy: 0.8995 - val_loss: 0.5086 - val_accuracy: 0.8470\n",
      "Epoch 35/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.9004 - lr: 0.00443 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2903 - accuracy: 0.9005 - val_loss: 0.6199 - val_accuracy: 0.8210\n",
      "Epoch 36/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2742 - accuracy: 0.9055 - lr: 0.00455 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2740 - accuracy: 0.9054 - val_loss: 0.8612 - val_accuracy: 0.7640\n",
      "Epoch 37/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2547 - accuracy: 0.9127 - lr: 0.00466 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2538 - accuracy: 0.9126 - val_loss: 0.4933 - val_accuracy: 0.8455\n",
      "Epoch 38/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9051 - lr: 0.00477 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2656 - accuracy: 0.9051 - val_loss: 0.5409 - val_accuracy: 0.8425\n",
      "Epoch 39/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2729 - accuracy: 0.9036 - lr: 0.00488 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2726 - accuracy: 0.9036 - val_loss: 0.4736 - val_accuracy: 0.8555\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.9042 - lr: 0.00500 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2854 - accuracy: 0.9042 - val_loss: 1.5315 - val_accuracy: 0.6470\n",
      "Epoch 41/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9220 - lr: 0.00489 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2158 - accuracy: 0.9226 - val_loss: 1.3700 - val_accuracy: 0.6805\n",
      "Epoch 42/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9192 - lr: 0.00478 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2324 - accuracy: 0.9192 - val_loss: 1.3701 - val_accuracy: 0.6755\n",
      "Epoch 43/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2203 - accuracy: 0.9212 - lr: 0.00467 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2207 - accuracy: 0.9210 - val_loss: 0.5170 - val_accuracy: 0.8455\n",
      "Epoch 44/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1994 - accuracy: 0.9293 - lr: 0.00455 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2000 - accuracy: 0.9294 - val_loss: 0.8337 - val_accuracy: 0.7785\n",
      "Epoch 45/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1836 - accuracy: 0.9349 - lr: 0.00444 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1837 - accuracy: 0.9351 - val_loss: 0.5688 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9400 - lr: 0.00433 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1709 - accuracy: 0.9399 - val_loss: 0.4227 - val_accuracy: 0.8760\n",
      "Epoch 47/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9411 - lr: 0.00422 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1665 - accuracy: 0.9411 - val_loss: 0.4836 - val_accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1551 - accuracy: 0.9433 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1542 - accuracy: 0.9438 - val_loss: 0.3895 - val_accuracy: 0.8920\n",
      "Epoch 49/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9503 - lr: 0.00399 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1416 - accuracy: 0.9504 - val_loss: 0.3620 - val_accuracy: 0.8930\n",
      "Epoch 50/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9584 - lr: 0.00388 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1218 - accuracy: 0.9586 - val_loss: 0.5317 - val_accuracy: 0.8565\n",
      "Epoch 51/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9598 - lr: 0.00377 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1118 - accuracy: 0.9594 - val_loss: 0.3609 - val_accuracy: 0.9010\n",
      "Epoch 52/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9590 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1147 - accuracy: 0.9590 - val_loss: 0.3321 - val_accuracy: 0.9075\n",
      "Epoch 53/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1095 - accuracy: 0.9610 - lr: 0.00354 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1088 - accuracy: 0.9614 - val_loss: 0.3417 - val_accuracy: 0.8965\n",
      "Epoch 54/100\n",
      "32/36 [=========================>....] - ETA: 0s - loss: 0.0996 - accuracy: 0.9658 - lr: 0.00343 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0999 - accuracy: 0.9659 - val_loss: 0.3422 - val_accuracy: 0.9095\n",
      "Epoch 55/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0938 - accuracy: 0.9681 - lr: 0.00332 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0942 - accuracy: 0.9678 - val_loss: 0.3666 - val_accuracy: 0.8910\n",
      "Epoch 56/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 0.9699 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0876 - accuracy: 0.9699 - val_loss: 0.3713 - val_accuracy: 0.8955\n",
      "Epoch 57/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0739 - accuracy: 0.9750 - lr: 0.00309 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.3768 - val_accuracy: 0.8960\n",
      "Epoch 58/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0823 - accuracy: 0.9716 - lr: 0.00298 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.3773 - val_accuracy: 0.8965\n",
      "Epoch 59/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9791 - lr: 0.00287 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0637 - accuracy: 0.9792 - val_loss: 0.3483 - val_accuracy: 0.9035\n",
      "Epoch 60/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9799 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9799 - val_loss: 0.4767 - val_accuracy: 0.8745\n",
      "Epoch 61/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0642 - accuracy: 0.9788 - lr: 0.00264 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0634 - accuracy: 0.9793 - val_loss: 0.4462 - val_accuracy: 0.8840\n",
      "Epoch 62/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9820 - lr: 0.00253 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9821 - val_loss: 0.3913 - val_accuracy: 0.8965\n",
      "Epoch 63/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0459 - accuracy: 0.9867 - lr: 0.00242 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 0.3461 - val_accuracy: 0.9100\n",
      "Epoch 64/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0441 - accuracy: 0.9878 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.3425 - val_accuracy: 0.9110\n",
      "Epoch 65/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0345 - accuracy: 0.9908 - lr: 0.00219 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.3789 - val_accuracy: 0.8965\n",
      "Epoch 66/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0307 - accuracy: 0.9938 - lr: 0.00208 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0313 - accuracy: 0.9937 - val_loss: 0.3390 - val_accuracy: 0.9150\n",
      "Epoch 67/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0298 - accuracy: 0.9941 - lr: 0.00197 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.3413 - val_accuracy: 0.9120\n",
      "Epoch 68/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0302 - accuracy: 0.9936 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.3457 - val_accuracy: 0.9115\n",
      "Epoch 69/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0244 - accuracy: 0.9961 - lr: 0.00174 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0243 - accuracy: 0.9961 - val_loss: 0.3466 - val_accuracy: 0.9140\n",
      "Epoch 70/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0215 - accuracy: 0.9970 - lr: 0.00163 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9971 - val_loss: 0.3421 - val_accuracy: 0.9140\n",
      "Epoch 71/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9979 - lr: 0.00152 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9979 - val_loss: 0.3464 - val_accuracy: 0.9160\n",
      "Epoch 72/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0176 - accuracy: 0.9986 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 0.3401 - val_accuracy: 0.9120\n",
      "Epoch 73/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9986 - lr: 0.00129 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0162 - accuracy: 0.9986 - val_loss: 0.3453 - val_accuracy: 0.9110\n",
      "Epoch 74/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9991 - lr: 0.00118 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0149 - accuracy: 0.9991 - val_loss: 0.3438 - val_accuracy: 0.9130\n",
      "Epoch 75/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0146 - accuracy: 0.9993 - lr: 0.00107 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9993 - val_loss: 0.3768 - val_accuracy: 0.9065\n",
      "Epoch 76/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0136 - accuracy: 0.9994 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.3630 - val_accuracy: 0.9105\n",
      "Epoch 77/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0128 - accuracy: 0.9998 - lr: 0.00084 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9998 - val_loss: 0.3615 - val_accuracy: 0.9125\n",
      "Epoch 78/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0124 - accuracy: 0.9996 - lr: 0.00073 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0125 - accuracy: 0.9996 - val_loss: 0.3627 - val_accuracy: 0.9115\n",
      "Epoch 79/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9997 - lr: 0.00062 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0121 - accuracy: 0.9997 - val_loss: 0.3584 - val_accuracy: 0.9120\n",
      "Epoch 80/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9998 - lr: 0.00050 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0115 - accuracy: 0.9998 - val_loss: 0.3588 - val_accuracy: 0.9095\n",
      "Epoch 81/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0111 - accuracy: 0.9998 - lr: 0.00048 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.3560 - val_accuracy: 0.9120\n",
      "Epoch 82/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0110 - accuracy: 0.9998 - lr: 0.00045 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9998 - val_loss: 0.3550 - val_accuracy: 0.9110\n",
      "Epoch 83/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9998 - lr: 0.00043 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9998 - val_loss: 0.3548 - val_accuracy: 0.9140\n",
      "Epoch 84/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9998 - lr: 0.00040 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.3559 - val_accuracy: 0.9155\n",
      "Epoch 85/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0106 - accuracy: 0.9999 - lr: 0.00038 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9999 - val_loss: 0.3516 - val_accuracy: 0.9130\n",
      "Epoch 86/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0104 - accuracy: 0.9999 - lr: 0.00035 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9999 - val_loss: 0.3546 - val_accuracy: 0.9130\n",
      "Epoch 87/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000 - lr: 0.00033 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9130\n",
      "Epoch 88/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0103 - accuracy: 0.9999 - lr: 0.00030 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0103 - accuracy: 0.9999 - val_loss: 0.3564 - val_accuracy: 0.9120\n",
      "Epoch 89/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0101 - accuracy: 0.9999 - lr: 0.00028 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9999 - val_loss: 0.3572 - val_accuracy: 0.9135\n",
      "Epoch 90/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000 - lr: 0.00025 \n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9115\n",
      "Epoch 91/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9999 - lr: 0.00023 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0099 - accuracy: 0.9999 - val_loss: 0.3573 - val_accuracy: 0.9110\n",
      "Epoch 92/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000 - lr: 0.00020 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9115\n",
      "Epoch 93/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9999 - lr: 0.00018 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 0.9999 - val_loss: 0.3580 - val_accuracy: 0.9140\n",
      "Epoch 94/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000 - lr: 0.00015 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9110\n",
      "Epoch 95/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000 - lr: 0.00013 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9120\n",
      "Epoch 96/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000 - lr: 0.00010 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9135\n",
      "Epoch 97/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000 - lr: 0.00008 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9120\n",
      "Epoch 98/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000 - lr: 0.00006 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9120\n",
      "Epoch 99/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000 - lr: 0.00003 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9120\n",
      "Epoch 100/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000 - lr: 0.00001 \n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9120\n",
      "\n",
      "############### Training Completed #################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#region Model Configuration\n",
    "MODEL_CONFIG = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 512,\n",
    "    'input_size': 600,\n",
    "    'learning_rate': 5e-3,\n",
    "    'model_save_path': './Model/Source_Model(RK1=0x35).h5'\n",
    "}\n",
    "#endregion\n",
    "\n",
    "#region Data Preparation\n",
    "# Load dataset with proper error handling\n",
    "\n",
    "(x_train, y_train, x_test, y_test, \n",
    "     p_train, p_test) = load_CW_Source(in_file='./DataSet/rk1=0x35/',sec=18000)\n",
    "\n",
    "\n",
    "# Preprocess targets\n",
    "y_train = y_train[:]\n",
    "y_test = y_test[:]\n",
    "\n",
    "# Shuffle training data\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "# Standardization and Normalization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train).astype('float32')\n",
    "x_test = scaler.transform(x_test).astype('float32')\n",
    "\n",
    "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = minmax_scaler.fit_transform(x_train)\n",
    "x_test = minmax_scaler.transform(x_test)\n",
    "#endregion\n",
    "\n",
    "\n",
    "#Model Initialization\n",
    "try:\n",
    "    model = cnn_classifier(\n",
    "        input_size=MODEL_CONFIG['input_size'],\n",
    "        learning_rate=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Model creation failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "#region Training Execution\n",
    "print(\"\\n############### Starting Training #################\\n\")\n",
    "try:\n",
    "    training_history = train_model(\n",
    "        x_train, y_train,\n",
    "        x_test, y_test,\n",
    "        model=model,\n",
    "        save_file_name=MODEL_CONFIG['model_save_path'],\n",
    "        epochs=MODEL_CONFIG['epochs'],\n",
    "        batch_size=MODEL_CONFIG['batch_size'],\n",
    "        max_lr=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n############### Training Completed #################\\n\")\n",
    "#endregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-krease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
