{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from utils.dataset_utils import batch_generator \n",
    "from DANN_trainer import DANN\n",
    "from utils.LoadData import load_CW_Source,load_CW_Target_validation\n",
    "from utils.DANN_config import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_main():\n",
    "    \"\"\"Main function for side-channel analysis using domain adaptation\"\"\"\n",
    "    # Initialize power trace parameters\n",
    "    power_input_shape = (800, 1)  # Original trace length and channels\n",
    "    trace_length = 800           # Renamed from image_size\n",
    "    init_learning_rate = 5e-4\n",
    "    momentum_rate = 0.9\n",
    "    batch_size = 2000\n",
    "    epochs = 60\n",
    "    pre_trained_path = None\n",
    "    output_path = 'E:\\DL_result\\DANN\\XMEGA_MDS_CT/'\n",
    "    profiling_Data_path='../Dataset/AES_device1/'\n",
    "    Target_Data_path='../Dataset/SM4_device1/'\n",
    "\n",
    "    for byte_num in range(0, 1):\n",
    "        print(f\"================ Processing Byte {byte_num} ================\")\n",
    "        \n",
    "        # Configure paths for SCA results\n",
    "        checkpoints_dir = os.path.abspath(output_path + f\"/models/byte={byte_num}\")\n",
    "        \n",
    "\n",
    "        # Create configuration object\n",
    "        sca_config=config(\n",
    "            pre_trained_path=pre_trained_path,\n",
    "            checkpoints_dir=checkpoints_dir,\n",
    "            power_input_shape=power_input_shape,\n",
    "            trace_length=trace_length,\n",
    "            init_learning_rate=init_learning_rate,\n",
    "            momentum_rate=momentum_rate,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs\n",
    "        )\n",
    "\n",
    "        # Load source device power traces\n",
    "        src_traces_train, src_labels_train,src_traces_val, src_labels_val,_,_ = load_CW_Source(\n",
    "            in_file=profiling_Data_path,\n",
    "            sec=18000,  # Fixed security parameter from original implementation\n",
    "            byte=byte_num\n",
    "        )\n",
    "        \n",
    "        # Convert labels for SCA classification (256 classes for byte values)\n",
    "        src_labels_train = to_categorical(src_labels_train).astype(np.float32)\n",
    "        src_labels_val = to_categorical(src_labels_val).astype(np.float32)\n",
    "\n",
    "        # Preprocess power traces\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        src_traces_train = scaler.fit_transform(src_traces_train)\n",
    "        src_traces_val = scaler.transform(src_traces_val)\n",
    "\n",
    "        # Load target device traces\n",
    "        # Note: Target domain labels are only used for validation accuracy, not for gradient updates\n",
    "        tgt_traces_train, tgt_labels_train, tgt_traces_val, tgt_labels_val, _,_ = load_CW_Target_validation(\n",
    "            in_file=Target_Data_path,\n",
    "            sec=18000,  # Fixed security parameter from original implementation\n",
    "            byte=byte_num\n",
    "        )\n",
    "       \n",
    "\n",
    "        # Process target device data\n",
    "        tgt_labels_train = to_categorical(tgt_labels_train).astype(np.float32)\n",
    "        tgt_labels_val = to_categorical(tgt_labels_val).astype(np.float32)\n",
    "        tgt_traces_train = scaler.transform(tgt_traces_train)\n",
    "        tgt_traces_val = scaler.transform(tgt_traces_val)\n",
    "\n",
    "        # Reshape traces for CNN input\n",
    "        src_traces_train = src_traces_train.reshape((-1, power_input_shape[0], 1))\n",
    "        tgt_traces_train = tgt_traces_train.reshape((-1, power_input_shape[0], 1))\n",
    "        tgt_traces_val = tgt_traces_val.reshape((-1, power_input_shape[0], 1))\n",
    "\n",
    "        # Create trace data generators\n",
    "        train_source_gen = batch_generator(\n",
    "            [src_traces_train, src_labels_train], \n",
    "            batch_size=batch_size//2\n",
    "        )\n",
    "        train_target_gen = batch_generator(\n",
    "            [tgt_traces_train, tgt_labels_train],\n",
    "            batch_size=batch_size//2,\n",
    "            shuffle=False\n",
    "        )\n",
    "        val_target_gen = batch_generator(\n",
    "            [tgt_traces_val, tgt_labels_val],\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Calculate training iterations\n",
    "        train_iters = max(\n",
    "            len(src_traces_train) // (batch_size//2),\n",
    "            len(tgt_traces_train) // (batch_size//2)\n",
    "        )\n",
    "        val_iters = len(tgt_traces_val) // batch_size\n",
    "\n",
    "        # Initialize fresh model session\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Initialize and train SCA model\n",
    "        sca_model = DANN(sca_config)\n",
    "        sca_model.train(train_source_gen,train_target_gen,val_target_gen,train_iters,val_iters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-krease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
