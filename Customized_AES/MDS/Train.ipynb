{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VirtualEnvironment\\Anaconda3\\envs\\TF-krease\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\VirtualEnvironment\\Anaconda3\\envs\\TF-krease\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "d:\\VirtualEnvironment\\Anaconda3\\envs\\TF-krease\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "d:\\VirtualEnvironment\\Anaconda3\\envs\\TF-krease\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "d:\\VirtualEnvironment\\Anaconda3\\envs\\TF-krease\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from utils.CLR import*\n",
    "from utils.LoadData import load_CW_Source\n",
    "from Model.CNN import cnn_classifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def train_model(X_profiling, Y_profiling, X_test, Y_test, model, save_file_name, epochs=150, batch_size=100,\n",
    "                max_lr=1e-3):\n",
    "\n",
    "    # Save model every epoch\n",
    "    save_model = ModelCheckpoint(\n",
    "                    filepath=save_file_name,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    save_best_only=True)\n",
    "\n",
    "    # Get the input layer shape\n",
    "    input_layer_shape = model.get_layer(index=0).input_shape[0]\n",
    "\n",
    "    # Sanity check\n",
    "    if input_layer_shape[1] != len(X_profiling[0]):\n",
    "        print(\"Error: model input shape %d instead of %d is not expected ...\" % (\n",
    "        input_layer_shape[1], len(X_profiling[0])))\n",
    "        sys.exit(-1)\n",
    "    Reshaped_X_profiling, Reshaped_X_test = X_profiling.reshape(\n",
    "        (X_profiling.shape[0], X_profiling.shape[1], 1)), X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # One Cycle Policy\n",
    "    lr_manager = OneCycleLR(max_lr=max_lr, end_percentage=0.2, scale_percentage=0.1, maximum_momentum=None,\n",
    "                            minimum_momentum=None, verbose=True)\n",
    "\n",
    "    callbacks = [save_model, lr_manager]\n",
    "\n",
    "    history = model.fit(x=Reshaped_X_profiling, y=to_categorical(Y_profiling, num_classes=256),\n",
    "                        validation_data=(Reshaped_X_test, to_categorical(Y_test, num_classes=256)),\n",
    "                        batch_size=batch_size, verbose=1, epochs=epochs, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 700, 1)]          0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 700, 4)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 700, 4)            16        \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 350, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1400)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 16)                22416     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               4352      \n",
      "=================================================================\n",
      "Total params: 27,064\n",
      "Trainable params: 27,056\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "\n",
      "############### Starting Training #################\n",
      "\n",
      "Epoch 1/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 5.5766 - accuracy: 0.0049 - lr: 0.00061 \n",
      "36/36 [==============================] - 1s 38ms/step - loss: 5.5761 - accuracy: 0.0049 - val_loss: 5.5656 - val_accuracy: 0.0053\n",
      "Epoch 2/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 5.4135 - accuracy: 0.0141 - lr: 0.00072 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 5.4113 - accuracy: 0.0143 - val_loss: 5.4804 - val_accuracy: 0.0080\n",
      "Epoch 3/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 5.1505 - accuracy: 0.0362 - lr: 0.00083 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 5.1494 - accuracy: 0.0362 - val_loss: 5.2409 - val_accuracy: 0.0284\n",
      "Epoch 4/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 4.7243 - accuracy: 0.0632 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 4.7154 - accuracy: 0.0644 - val_loss: 4.7917 - val_accuracy: 0.0669\n",
      "Epoch 5/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 4.1136 - accuracy: 0.1295 - lr: 0.00106 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 4.1129 - accuracy: 0.1295 - val_loss: 4.1399 - val_accuracy: 0.1471\n",
      "Epoch 6/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 3.2949 - accuracy: 0.2341 - lr: 0.00117 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 3.2932 - accuracy: 0.2343 - val_loss: 3.3060 - val_accuracy: 0.2441\n",
      "Epoch 7/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 2.5835 - accuracy: 0.3370 - lr: 0.00128 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 2.5759 - accuracy: 0.3378 - val_loss: 2.6802 - val_accuracy: 0.3275\n",
      "Epoch 8/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 2.1656 - accuracy: 0.4112 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 2.1624 - accuracy: 0.4128 - val_loss: 2.3071 - val_accuracy: 0.3864\n",
      "Epoch 9/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 1.9011 - accuracy: 0.4674 - lr: 0.00151 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 1.9010 - accuracy: 0.4674 - val_loss: 2.0982 - val_accuracy: 0.4265\n",
      "Epoch 10/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.7225 - accuracy: 0.5109 - lr: 0.00162 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 1.7226 - accuracy: 0.5108 - val_loss: 1.9124 - val_accuracy: 0.4620\n",
      "Epoch 11/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.5546 - accuracy: 0.5513 - lr: 0.00173 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 1.5542 - accuracy: 0.5516 - val_loss: 1.7908 - val_accuracy: 0.4871\n",
      "Epoch 12/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.4426 - accuracy: 0.5776 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 1.4430 - accuracy: 0.5775 - val_loss: 1.6835 - val_accuracy: 0.5160\n",
      "Epoch 13/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.3217 - accuracy: 0.6080 - lr: 0.00196 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 1.3208 - accuracy: 0.6084 - val_loss: 1.5808 - val_accuracy: 0.5496\n",
      "Epoch 14/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.2297 - accuracy: 0.6348 - lr: 0.00207 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 1.2298 - accuracy: 0.6350 - val_loss: 1.5658 - val_accuracy: 0.5536\n",
      "Epoch 15/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.1516 - accuracy: 0.6556 - lr: 0.00218 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 1.1514 - accuracy: 0.6557 - val_loss: 1.4659 - val_accuracy: 0.5791\n",
      "Epoch 16/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 1.0618 - accuracy: 0.6792 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 1.0615 - accuracy: 0.6805 - val_loss: 1.4399 - val_accuracy: 0.5883\n",
      "Epoch 17/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.6903 - lr: 0.00241 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 1.0129 - accuracy: 0.6904 - val_loss: 1.3494 - val_accuracy: 0.6120\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9399 - accuracy: 0.7097 - lr: 0.00252 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.9399 - accuracy: 0.7097 - val_loss: 1.3182 - val_accuracy: 0.6167\n",
      "Epoch 19/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.8768 - accuracy: 0.7287 - lr: 0.00263 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.8803 - accuracy: 0.7280 - val_loss: 1.2908 - val_accuracy: 0.6289\n",
      "Epoch 20/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.8273 - accuracy: 0.7402 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.8282 - accuracy: 0.7401 - val_loss: 1.2251 - val_accuracy: 0.6455\n",
      "Epoch 21/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.7667 - accuracy: 0.7567 - lr: 0.00286 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.7675 - accuracy: 0.7566 - val_loss: 1.2278 - val_accuracy: 0.6511\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.7419 - accuracy: 0.7616 - lr: 0.00297 \n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.7419 - accuracy: 0.7616 - val_loss: 1.1334 - val_accuracy: 0.6711\n",
      "Epoch 23/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.7049 - accuracy: 0.7751 - lr: 0.00308 \n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.7051 - accuracy: 0.7754 - val_loss: 1.1361 - val_accuracy: 0.6747\n",
      "Epoch 24/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.7861 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6678 - accuracy: 0.7863 - val_loss: 1.1583 - val_accuracy: 0.6721\n",
      "Epoch 25/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.6419 - accuracy: 0.7926 - lr: 0.00331 \n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6418 - accuracy: 0.7927 - val_loss: 1.1527 - val_accuracy: 0.6763\n",
      "Epoch 26/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.6322 - accuracy: 0.7925 - lr: 0.00342 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.6317 - accuracy: 0.7928 - val_loss: 1.1579 - val_accuracy: 0.6759\n",
      "Epoch 27/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.8109 - lr: 0.00353 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.5883 - accuracy: 0.8112 - val_loss: 1.0776 - val_accuracy: 0.6965\n",
      "Epoch 28/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.8232 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.5446 - accuracy: 0.8231 - val_loss: 1.1123 - val_accuracy: 0.6924\n",
      "Epoch 29/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.8246 - lr: 0.00376 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.5457 - accuracy: 0.8246 - val_loss: 1.1010 - val_accuracy: 0.6945\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.8219 - lr: 0.00387 \n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.5413 - accuracy: 0.8219 - val_loss: 1.1851 - val_accuracy: 0.6796\n",
      "Epoch 31/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5183 - accuracy: 0.8274 - lr: 0.00398 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.5177 - accuracy: 0.8275 - val_loss: 1.1286 - val_accuracy: 0.6964\n",
      "Epoch 32/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.5034 - accuracy: 0.8348 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.5030 - accuracy: 0.8348 - val_loss: 1.1176 - val_accuracy: 0.6988\n",
      "Epoch 33/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.8435 - lr: 0.00421 \n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.4781 - accuracy: 0.8431 - val_loss: 1.0599 - val_accuracy: 0.7080\n",
      "Epoch 34/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8383 - lr: 0.00432 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.4851 - accuracy: 0.8379 - val_loss: 1.1108 - val_accuracy: 0.6991\n",
      "Epoch 35/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.8497 - lr: 0.00443 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.4576 - accuracy: 0.8497 - val_loss: 1.0737 - val_accuracy: 0.7057\n",
      "Epoch 36/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.4469 - accuracy: 0.8504 - lr: 0.00455 \n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.4487 - accuracy: 0.8502 - val_loss: 1.0571 - val_accuracy: 0.7157\n",
      "Epoch 37/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.4275 - accuracy: 0.8569 - lr: 0.00466 \n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.4310 - accuracy: 0.8559 - val_loss: 1.0456 - val_accuracy: 0.7232\n",
      "Epoch 38/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.8585 - lr: 0.00477 \n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.4307 - accuracy: 0.8585 - val_loss: 1.1879 - val_accuracy: 0.6977\n",
      "Epoch 39/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.8629 - lr: 0.00488 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.4132 - accuracy: 0.8628 - val_loss: 1.1514 - val_accuracy: 0.7044\n",
      "Epoch 40/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3886 - accuracy: 0.8693 - lr: 0.00500 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.3914 - accuracy: 0.8688 - val_loss: 1.1168 - val_accuracy: 0.7091\n",
      "Epoch 41/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8701 - lr: 0.00489 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.3800 - accuracy: 0.8701 - val_loss: 1.1054 - val_accuracy: 0.7169\n",
      "Epoch 42/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3693 - accuracy: 0.8761 - lr: 0.00478 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.3704 - accuracy: 0.8757 - val_loss: 1.0542 - val_accuracy: 0.7279\n",
      "Epoch 43/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3730 - accuracy: 0.8728 - lr: 0.00467 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.3730 - accuracy: 0.8729 - val_loss: 1.0721 - val_accuracy: 0.7271\n",
      "Epoch 44/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.8939 - lr: 0.00455 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.3210 - accuracy: 0.8941 - val_loss: 1.0039 - val_accuracy: 0.7381\n",
      "Epoch 45/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9026 - lr: 0.00444 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.2832 - accuracy: 0.9024 - val_loss: 1.0612 - val_accuracy: 0.7351\n",
      "Epoch 46/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2881 - accuracy: 0.9006 - lr: 0.00433 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.2875 - accuracy: 0.9008 - val_loss: 1.0855 - val_accuracy: 0.7307\n",
      "Epoch 47/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9102 - lr: 0.00422 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.2646 - accuracy: 0.9098 - val_loss: 1.0991 - val_accuracy: 0.7335\n",
      "Epoch 48/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9040 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.2811 - accuracy: 0.9032 - val_loss: 1.1199 - val_accuracy: 0.7356\n",
      "Epoch 49/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9095 - lr: 0.00399 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.2566 - accuracy: 0.9092 - val_loss: 1.1315 - val_accuracy: 0.7379\n",
      "Epoch 50/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9133 - lr: 0.00388 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2516 - accuracy: 0.9133 - val_loss: 1.1349 - val_accuracy: 0.7393\n",
      "Epoch 51/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2255 - accuracy: 0.9227 - lr: 0.00377 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2292 - accuracy: 0.9217 - val_loss: 1.1473 - val_accuracy: 0.7355\n",
      "Epoch 52/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9233 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2273 - accuracy: 0.9231 - val_loss: 1.1747 - val_accuracy: 0.7375\n",
      "Epoch 53/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2291 - accuracy: 0.9208 - lr: 0.00354 \n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2298 - accuracy: 0.9205 - val_loss: 1.1733 - val_accuracy: 0.7427\n",
      "Epoch 54/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2016 - accuracy: 0.9281 - lr: 0.00343 \n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.2029 - accuracy: 0.9278 - val_loss: 1.1827 - val_accuracy: 0.7396\n",
      "Epoch 55/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9441 - lr: 0.00332 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.1667 - accuracy: 0.9443 - val_loss: 1.2000 - val_accuracy: 0.7363\n",
      "Epoch 56/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9531 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.1483 - accuracy: 0.9529 - val_loss: 1.2125 - val_accuracy: 0.7436\n",
      "Epoch 57/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9480 - lr: 0.00309 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.1570 - accuracy: 0.9481 - val_loss: 1.2194 - val_accuracy: 0.7459\n",
      "Epoch 58/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9564 - lr: 0.00298 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.1331 - accuracy: 0.9563 - val_loss: 1.2419 - val_accuracy: 0.7495\n",
      "Epoch 59/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9563 - lr: 0.00287 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.1310 - accuracy: 0.9563 - val_loss: 1.3001 - val_accuracy: 0.7432\n",
      "Epoch 60/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9600 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.1210 - accuracy: 0.9602 - val_loss: 1.3108 - val_accuracy: 0.7449\n",
      "Epoch 61/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9668 - lr: 0.00264 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.1058 - accuracy: 0.9668 - val_loss: 1.3259 - val_accuracy: 0.7435\n",
      "Epoch 62/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.9666 - lr: 0.00253 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.1049 - accuracy: 0.9664 - val_loss: 1.3652 - val_accuracy: 0.7401\n",
      "Epoch 63/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9725 - lr: 0.00242 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0906 - accuracy: 0.9726 - val_loss: 1.3880 - val_accuracy: 0.7431\n",
      "Epoch 64/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0796 - accuracy: 0.9783 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0798 - accuracy: 0.9784 - val_loss: 1.3841 - val_accuracy: 0.7457\n",
      "Epoch 65/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9807 - lr: 0.00219 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 1.4230 - val_accuracy: 0.7437\n",
      "Epoch 66/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0694 - accuracy: 0.9832 - lr: 0.00208 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0693 - accuracy: 0.9832 - val_loss: 1.4252 - val_accuracy: 0.7471\n",
      "Epoch 67/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9857 - lr: 0.00197 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0602 - accuracy: 0.9857 - val_loss: 1.4410 - val_accuracy: 0.7491\n",
      "Epoch 68/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9906 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0493 - accuracy: 0.9906 - val_loss: 1.4568 - val_accuracy: 0.7480\n",
      "Epoch 69/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9944 - lr: 0.00174 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0408 - accuracy: 0.9944 - val_loss: 1.4829 - val_accuracy: 0.7484\n",
      "Epoch 70/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0356 - accuracy: 0.9966 - lr: 0.00163 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0355 - accuracy: 0.9966 - val_loss: 1.5068 - val_accuracy: 0.7459\n",
      "Epoch 71/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0319 - accuracy: 0.9977 - lr: 0.00152 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0317 - accuracy: 0.9978 - val_loss: 1.5163 - val_accuracy: 0.7445\n",
      "Epoch 72/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0273 - accuracy: 0.9989 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0273 - accuracy: 0.9989 - val_loss: 1.5259 - val_accuracy: 0.7481\n",
      "Epoch 73/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9993 - lr: 0.00129 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0244 - accuracy: 0.9993 - val_loss: 1.5380 - val_accuracy: 0.7476\n",
      "Epoch 74/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9997 - lr: 0.00118 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0224 - accuracy: 0.9997 - val_loss: 1.5505 - val_accuracy: 0.7487\n",
      "Epoch 75/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9998 - lr: 0.00107 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0208 - accuracy: 0.9998 - val_loss: 1.5636 - val_accuracy: 0.7476\n",
      "Epoch 76/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9999 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0193 - accuracy: 0.9999 - val_loss: 1.5729 - val_accuracy: 0.7483\n",
      "Epoch 77/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9999 - lr: 0.00084 \n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.0186 - accuracy: 0.9999 - val_loss: 1.5811 - val_accuracy: 0.7475\n",
      "Epoch 78/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9999 - lr: 0.00073 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0174 - accuracy: 0.9999 - val_loss: 1.5874 - val_accuracy: 0.7488\n",
      "Epoch 79/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9999 - lr: 0.00062 \n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.0168 - accuracy: 0.9999 - val_loss: 1.5931 - val_accuracy: 0.7471\n",
      "Epoch 80/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000 - lr: 0.00050 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.7483\n",
      "Epoch 81/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000 - lr: 0.00048 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.6041 - val_accuracy: 0.7477\n",
      "Epoch 82/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000 - lr: 0.00045 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.6080 - val_accuracy: 0.7479\n",
      "Epoch 83/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000 - lr: 0.00043 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.6144 - val_accuracy: 0.7481\n",
      "Epoch 84/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000 - lr: 0.00040 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.6180 - val_accuracy: 0.7487\n",
      "Epoch 85/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000 - lr: 0.00038 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.6226 - val_accuracy: 0.7487\n",
      "Epoch 86/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000 - lr: 0.00035 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.6262 - val_accuracy: 0.7483\n",
      "Epoch 87/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000 - lr: 0.00033 \n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.6301 - val_accuracy: 0.7485\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000 - lr: 0.00030 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.7471\n",
      "Epoch 89/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000 - lr: 0.00028 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.6371 - val_accuracy: 0.7477\n",
      "Epoch 90/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000 - lr: 0.00025 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.6399 - val_accuracy: 0.7488\n",
      "Epoch 91/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000 - lr: 0.00023 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.6431 - val_accuracy: 0.7476\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000 - lr: 0.00020 \n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.6454 - val_accuracy: 0.7473\n",
      "Epoch 93/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000 - lr: 0.00018 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.6475 - val_accuracy: 0.7467\n",
      "Epoch 94/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000 - lr: 0.00015 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.7475\n",
      "Epoch 95/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000 - lr: 0.00013 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.7475\n",
      "Epoch 96/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000 - lr: 0.00010 \n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.6519 - val_accuracy: 0.7479\n",
      "Epoch 97/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 1.0000 - lr: 0.00008 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.6529 - val_accuracy: 0.7477\n",
      "Epoch 98/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000 - lr: 0.00006 \n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.7477\n",
      "Epoch 99/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000 - lr: 0.00003 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.6540 - val_accuracy: 0.7479\n",
      "Epoch 100/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000 - lr: 0.00001 \n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.6540 - val_accuracy: 0.7476\n",
      "\n",
      "############### Training Completed #################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#region Model Configuration\n",
    "MODEL_CONFIG = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 512,\n",
    "    'input_size': 700,\n",
    "    'learning_rate': 5e-3,\n",
    "    'attack_traces': 5000,\n",
    "    'model_save_path': './Model/Source_Model(Original MDS).h5'\n",
    "}\n",
    "#endregion\n",
    "\n",
    "#region Data Preparation\n",
    "# Load dataset with proper error handling\n",
    "\n",
    "(x_train, y_train, x_test, y_test, \n",
    "     p_train, p_test) = load_CW_Source(in_file='./DataSet/AES_OriginalMDS/',sec=18000)\n",
    "\n",
    "\n",
    "# Preprocess targets\n",
    "y_train = y_train[:, 0]\n",
    "y_test = y_test[:, 0]\n",
    "\n",
    "# Shuffle training data\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "# Standardization and Normalization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train).astype('float32')\n",
    "x_test = scaler.transform(x_test).astype('float32')\n",
    "\n",
    "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = minmax_scaler.fit_transform(x_train)\n",
    "x_test = minmax_scaler.transform(x_test)\n",
    "#endregion\n",
    "\n",
    "\n",
    "#Model Initialization\n",
    "try:\n",
    "    model = cnn_classifier(\n",
    "        input_size=MODEL_CONFIG['input_size'],\n",
    "        learning_rate=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Model creation failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "#region Training Execution\n",
    "print(\"\\n############### Starting Training #################\\n\")\n",
    "try:\n",
    "    training_history = train_model(\n",
    "        x_train, y_train,\n",
    "        x_test, y_test,\n",
    "        model=model,\n",
    "        save_file_name=MODEL_CONFIG['model_save_path'],\n",
    "        epochs=MODEL_CONFIG['epochs'],\n",
    "        batch_size=MODEL_CONFIG['batch_size'],\n",
    "        max_lr=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n############### Training Completed #################\\n\")\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 700, 1)]          0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 700, 4)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 700, 4)            16        \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 350, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1400)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 16)                22416     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               4352      \n",
      "=================================================================\n",
      "Total params: 27,064\n",
      "Trainable params: 27,056\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "\n",
      "############### Starting Training #################\n",
      "\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.5679 - accuracy: 0.0040 - lr: 0.00061 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.5679 - accuracy: 0.0041 - val_loss: 5.5581 - val_accuracy: 0.0047\n",
      "Epoch 2/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.5478 - accuracy: 0.0050 - lr: 0.00072 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.5478 - accuracy: 0.0050 - val_loss: 5.5487 - val_accuracy: 0.0045\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.5383 - accuracy: 0.0054 - lr: 0.00084 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.5382 - accuracy: 0.0055 - val_loss: 5.5436 - val_accuracy: 0.0052\n",
      "Epoch 4/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.5293 - accuracy: 0.0066 - lr: 0.00095 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.5293 - accuracy: 0.0066 - val_loss: 5.5387 - val_accuracy: 0.0060\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.5199 - accuracy: 0.0071 - lr: 0.00106 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.5199 - accuracy: 0.0071 - val_loss: 5.5353 - val_accuracy: 0.0058\n",
      "Epoch 6/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.5117 - accuracy: 0.0080 - lr: 0.00117 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.5119 - accuracy: 0.0079 - val_loss: 5.5389 - val_accuracy: 0.0080\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.5019 - accuracy: 0.0089 - lr: 0.00129 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.5019 - accuracy: 0.0089 - val_loss: 5.5282 - val_accuracy: 0.0082\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.4872 - accuracy: 0.0090 - lr: 0.00140 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.4872 - accuracy: 0.0090 - val_loss: 5.5292 - val_accuracy: 0.0082\n",
      "Epoch 9/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.4659 - accuracy: 0.0104 - lr: 0.00151 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.4658 - accuracy: 0.0104 - val_loss: 5.5147 - val_accuracy: 0.0090\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.4452 - accuracy: 0.0108 - lr: 0.00162 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.4452 - accuracy: 0.0108 - val_loss: 5.4921 - val_accuracy: 0.0104\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.4269 - accuracy: 0.0119 - lr: 0.00174 \n",
      "157/157 [==============================] - 5s 35ms/step - loss: 5.4269 - accuracy: 0.0119 - val_loss: 5.4926 - val_accuracy: 0.0086\n",
      "Epoch 12/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.4106 - accuracy: 0.0137 - lr: 0.00185 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.4108 - accuracy: 0.0137 - val_loss: 5.4970 - val_accuracy: 0.0094\n",
      "Epoch 13/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3973 - accuracy: 0.0138 - lr: 0.00196 \n",
      "157/157 [==============================] - 5s 29ms/step - loss: 5.3971 - accuracy: 0.0138 - val_loss: 5.4611 - val_accuracy: 0.0110\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3850 - accuracy: 0.0136 - lr: 0.00207 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.3852 - accuracy: 0.0136 - val_loss: 5.4661 - val_accuracy: 0.0094\n",
      "Epoch 15/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3743 - accuracy: 0.0138 - lr: 0.00219 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.3744 - accuracy: 0.0138 - val_loss: 5.4453 - val_accuracy: 0.0103\n",
      "Epoch 16/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3646 - accuracy: 0.0147 - lr: 0.00230 \n",
      "157/157 [==============================] - 5s 30ms/step - loss: 5.3643 - accuracy: 0.0147 - val_loss: 5.6184 - val_accuracy: 0.0075\n",
      "Epoch 17/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3577 - accuracy: 0.0150 - lr: 0.00241 \n",
      "157/157 [==============================] - 5s 30ms/step - loss: 5.3576 - accuracy: 0.0149 - val_loss: 5.5987 - val_accuracy: 0.0061\n",
      "Epoch 18/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3466 - accuracy: 0.0149 - lr: 0.00252 \n",
      "157/157 [==============================] - 4s 27ms/step - loss: 5.3466 - accuracy: 0.0149 - val_loss: 5.5520 - val_accuracy: 0.0076\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3413 - accuracy: 0.0154 - lr: 0.00264 \n",
      "157/157 [==============================] - 5s 29ms/step - loss: 5.3412 - accuracy: 0.0154 - val_loss: 5.8338 - val_accuracy: 0.0057\n",
      "Epoch 20/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3360 - accuracy: 0.0156 - lr: 0.00275 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.3366 - accuracy: 0.0156 - val_loss: 5.4702 - val_accuracy: 0.0091\n",
      "Epoch 21/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3304 - accuracy: 0.0156 - lr: 0.00286 \n",
      "157/157 [==============================] - 5s 29ms/step - loss: 5.3304 - accuracy: 0.0156 - val_loss: 5.4703 - val_accuracy: 0.0093\n",
      "Epoch 22/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3281 - accuracy: 0.0157 - lr: 0.00297 \n",
      "157/157 [==============================] - 5s 30ms/step - loss: 5.3283 - accuracy: 0.0156 - val_loss: 5.4749 - val_accuracy: 0.0083\n",
      "Epoch 23/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3235 - accuracy: 0.0157 - lr: 0.00309 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.3235 - accuracy: 0.0157 - val_loss: 5.5442 - val_accuracy: 0.0086\n",
      "Epoch 24/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3242 - accuracy: 0.0153 - lr: 0.00320 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.3243 - accuracy: 0.0153 - val_loss: 5.4669 - val_accuracy: 0.0120\n",
      "Epoch 25/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3163 - accuracy: 0.0156 - lr: 0.00331 \n",
      "157/157 [==============================] - 5s 35ms/step - loss: 5.3165 - accuracy: 0.0156 - val_loss: 5.4646 - val_accuracy: 0.0107\n",
      "Epoch 26/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3152 - accuracy: 0.0157 - lr: 0.00342 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.3152 - accuracy: 0.0158 - val_loss: 5.5410 - val_accuracy: 0.0091\n",
      "Epoch 27/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3126 - accuracy: 0.0167 - lr: 0.00354 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.3129 - accuracy: 0.0167 - val_loss: 5.5132 - val_accuracy: 0.0096\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.3077 - accuracy: 0.0166 - lr: 0.00365 \n",
      "157/157 [==============================] - 6s 37ms/step - loss: 5.3077 - accuracy: 0.0166 - val_loss: 5.5094 - val_accuracy: 0.0084\n",
      "Epoch 29/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3064 - accuracy: 0.0171 - lr: 0.00376 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.3063 - accuracy: 0.0171 - val_loss: 5.4312 - val_accuracy: 0.0113\n",
      "Epoch 30/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3072 - accuracy: 0.0165 - lr: 0.00387 \n",
      "157/157 [==============================] - 6s 38ms/step - loss: 5.3072 - accuracy: 0.0165 - val_loss: 5.4360 - val_accuracy: 0.0111\n",
      "Epoch 31/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.3036 - accuracy: 0.0173 - lr: 0.00399 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.3035 - accuracy: 0.0172 - val_loss: 5.4486 - val_accuracy: 0.0097\n",
      "Epoch 32/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2997 - accuracy: 0.0165 - lr: 0.00410 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.2998 - accuracy: 0.0165 - val_loss: 5.4410 - val_accuracy: 0.0102\n",
      "Epoch 33/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2961 - accuracy: 0.0173 - lr: 0.00421 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2962 - accuracy: 0.0173 - val_loss: 5.4169 - val_accuracy: 0.0110\n",
      "Epoch 34/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2963 - accuracy: 0.0172 - lr: 0.00432 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2966 - accuracy: 0.0171 - val_loss: 5.4214 - val_accuracy: 0.0102\n",
      "Epoch 35/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2973 - accuracy: 0.0171 - lr: 0.00444 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2973 - accuracy: 0.0171 - val_loss: 5.4630 - val_accuracy: 0.0104\n",
      "Epoch 36/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2968 - accuracy: 0.0176 - lr: 0.00455 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2968 - accuracy: 0.0176 - val_loss: 5.4254 - val_accuracy: 0.0112\n",
      "Epoch 37/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2934 - accuracy: 0.0178 - lr: 0.00466 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2934 - accuracy: 0.0179 - val_loss: 5.8602 - val_accuracy: 0.0075\n",
      "Epoch 38/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2940 - accuracy: 0.0172 - lr: 0.00477 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2940 - accuracy: 0.0172 - val_loss: 5.5304 - val_accuracy: 0.0091\n",
      "Epoch 39/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2907 - accuracy: 0.0174 - lr: 0.00489 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2909 - accuracy: 0.0174 - val_loss: 5.4798 - val_accuracy: 0.0103\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.2915 - accuracy: 0.0170 - lr: 0.00500 \n",
      "157/157 [==============================] - 5s 35ms/step - loss: 5.2915 - accuracy: 0.0170 - val_loss: 5.5374 - val_accuracy: 0.0100\n",
      "Epoch 41/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2872 - accuracy: 0.0176 - lr: 0.00489 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2871 - accuracy: 0.0177 - val_loss: 5.6487 - val_accuracy: 0.0094\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.2838 - accuracy: 0.0181 - lr: 0.00478 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.2838 - accuracy: 0.0181 - val_loss: 5.4575 - val_accuracy: 0.0102\n",
      "Epoch 43/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2806 - accuracy: 0.0179 - lr: 0.00466 \n",
      "157/157 [==============================] - 5s 35ms/step - loss: 5.2807 - accuracy: 0.0179 - val_loss: 5.8129 - val_accuracy: 0.0083\n",
      "Epoch 44/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2760 - accuracy: 0.0183 - lr: 0.00455 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2760 - accuracy: 0.0183 - val_loss: 5.5190 - val_accuracy: 0.0090\n",
      "Epoch 45/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2749 - accuracy: 0.0189 - lr: 0.00444 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2751 - accuracy: 0.0189 - val_loss: 5.4484 - val_accuracy: 0.0107\n",
      "Epoch 46/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2730 - accuracy: 0.0188 - lr: 0.00433 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2731 - accuracy: 0.0188 - val_loss: 6.0003 - val_accuracy: 0.0060\n",
      "Epoch 47/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2692 - accuracy: 0.0187 - lr: 0.00421 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2694 - accuracy: 0.0187 - val_loss: 5.4364 - val_accuracy: 0.0089\n",
      "Epoch 48/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2684 - accuracy: 0.0190 - lr: 0.00410 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.2685 - accuracy: 0.0191 - val_loss: 5.4523 - val_accuracy: 0.0099\n",
      "Epoch 49/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2670 - accuracy: 0.0187 - lr: 0.00399 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2670 - accuracy: 0.0187 - val_loss: 5.4774 - val_accuracy: 0.0105\n",
      "Epoch 50/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2633 - accuracy: 0.0196 - lr: 0.00388 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2631 - accuracy: 0.0196 - val_loss: 5.5098 - val_accuracy: 0.0109\n",
      "Epoch 51/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2596 - accuracy: 0.0189 - lr: 0.00376 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2598 - accuracy: 0.0189 - val_loss: 5.4429 - val_accuracy: 0.0105\n",
      "Epoch 52/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2596 - accuracy: 0.0196 - lr: 0.00365 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2598 - accuracy: 0.0196 - val_loss: 5.4427 - val_accuracy: 0.0110\n",
      "Epoch 53/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2544 - accuracy: 0.0200 - lr: 0.00354 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2546 - accuracy: 0.0200 - val_loss: 5.4357 - val_accuracy: 0.0110\n",
      "Epoch 54/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2533 - accuracy: 0.0202 - lr: 0.00343 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.2531 - accuracy: 0.0202 - val_loss: 5.5061 - val_accuracy: 0.0109\n",
      "Epoch 55/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2525 - accuracy: 0.0196 - lr: 0.00331 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2526 - accuracy: 0.0195 - val_loss: 5.4309 - val_accuracy: 0.0093\n",
      "Epoch 56/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2506 - accuracy: 0.0201 - lr: 0.00320 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2505 - accuracy: 0.0201 - val_loss: 5.4406 - val_accuracy: 0.0120\n",
      "Epoch 57/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2474 - accuracy: 0.0207 - lr: 0.00309 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2473 - accuracy: 0.0207 - val_loss: 5.4358 - val_accuracy: 0.0099\n",
      "Epoch 58/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2449 - accuracy: 0.0202 - lr: 0.00298 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2452 - accuracy: 0.0202 - val_loss: 5.4739 - val_accuracy: 0.0103\n",
      "Epoch 59/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2444 - accuracy: 0.0201 - lr: 0.00286 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.2445 - accuracy: 0.0201 - val_loss: 5.4377 - val_accuracy: 0.0102\n",
      "Epoch 60/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2402 - accuracy: 0.0207 - lr: 0.00275 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2403 - accuracy: 0.0207 - val_loss: 5.4300 - val_accuracy: 0.0099\n",
      "Epoch 61/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2400 - accuracy: 0.0209 - lr: 0.00264 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2398 - accuracy: 0.0209 - val_loss: 5.4632 - val_accuracy: 0.0099\n",
      "Epoch 62/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2374 - accuracy: 0.0217 - lr: 0.00253 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2372 - accuracy: 0.0217 - val_loss: 5.4311 - val_accuracy: 0.0100\n",
      "Epoch 63/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2346 - accuracy: 0.0213 - lr: 0.00241 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2347 - accuracy: 0.0213 - val_loss: 5.4424 - val_accuracy: 0.0101\n",
      "Epoch 64/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2320 - accuracy: 0.0214 - lr: 0.00230 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2320 - accuracy: 0.0214 - val_loss: 5.4453 - val_accuracy: 0.0105\n",
      "Epoch 65/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2297 - accuracy: 0.0214 - lr: 0.00219 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2298 - accuracy: 0.0213 - val_loss: 5.4551 - val_accuracy: 0.0104\n",
      "Epoch 66/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2286 - accuracy: 0.0220 - lr: 0.00208 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2285 - accuracy: 0.0220 - val_loss: 5.4649 - val_accuracy: 0.0101\n",
      "Epoch 67/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2266 - accuracy: 0.0218 - lr: 0.00196 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2266 - accuracy: 0.0218 - val_loss: 5.4559 - val_accuracy: 0.0105\n",
      "Epoch 68/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2246 - accuracy: 0.0218 - lr: 0.00185 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2247 - accuracy: 0.0218 - val_loss: 5.4687 - val_accuracy: 0.0103\n",
      "Epoch 69/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2215 - accuracy: 0.0222 - lr: 0.00174 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2216 - accuracy: 0.0222 - val_loss: 5.4489 - val_accuracy: 0.0098\n",
      "Epoch 70/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2214 - accuracy: 0.0225 - lr: 0.00163 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2214 - accuracy: 0.0225 - val_loss: 5.4463 - val_accuracy: 0.0093\n",
      "Epoch 71/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2180 - accuracy: 0.0221 - lr: 0.00151 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.2179 - accuracy: 0.0221 - val_loss: 5.4582 - val_accuracy: 0.0106\n",
      "Epoch 72/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2162 - accuracy: 0.0228 - lr: 0.00140 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2164 - accuracy: 0.0227 - val_loss: 5.4415 - val_accuracy: 0.0096\n",
      "Epoch 73/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2136 - accuracy: 0.0228 - lr: 0.00129 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2135 - accuracy: 0.0227 - val_loss: 5.4654 - val_accuracy: 0.0100\n",
      "Epoch 74/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2123 - accuracy: 0.0230 - lr: 0.00118 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2124 - accuracy: 0.0230 - val_loss: 5.4557 - val_accuracy: 0.0097\n",
      "Epoch 75/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2099 - accuracy: 0.0227 - lr: 0.00106 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.2099 - accuracy: 0.0227 - val_loss: 5.4520 - val_accuracy: 0.0095\n",
      "Epoch 76/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2080 - accuracy: 0.0237 - lr: 0.00095 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.2080 - accuracy: 0.0236 - val_loss: 5.4537 - val_accuracy: 0.0105\n",
      "Epoch 77/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2066 - accuracy: 0.0232 - lr: 0.00084 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.2067 - accuracy: 0.0232 - val_loss: 5.4563 - val_accuracy: 0.0106\n",
      "Epoch 78/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.2038 - accuracy: 0.0235 - lr: 0.00073 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2036 - accuracy: 0.0236 - val_loss: 5.4453 - val_accuracy: 0.0104\n",
      "Epoch 79/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2019 - accuracy: 0.0235 - lr: 0.00061 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.2020 - accuracy: 0.0235 - val_loss: 5.4574 - val_accuracy: 0.0097\n",
      "Epoch 80/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1999 - accuracy: 0.0241 - lr: 0.00050 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1998 - accuracy: 0.0242 - val_loss: 5.4483 - val_accuracy: 0.0108\n",
      "Epoch 81/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1985 - accuracy: 0.0240 - lr: 0.00048 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1983 - accuracy: 0.0241 - val_loss: 5.4490 - val_accuracy: 0.0106\n",
      "Epoch 82/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1975 - accuracy: 0.0241 - lr: 0.00045 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1974 - accuracy: 0.0240 - val_loss: 5.4496 - val_accuracy: 0.0107\n",
      "Epoch 83/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1972 - accuracy: 0.0240 - lr: 0.00043 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1972 - accuracy: 0.0240 - val_loss: 5.4480 - val_accuracy: 0.0103\n",
      "Epoch 84/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1965 - accuracy: 0.0240 - lr: 0.00040 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1963 - accuracy: 0.0240 - val_loss: 5.4523 - val_accuracy: 0.0115\n",
      "Epoch 85/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1959 - accuracy: 0.0245 - lr: 0.00038 \n",
      "157/157 [==============================] - 5s 31ms/step - loss: 5.1960 - accuracy: 0.0245 - val_loss: 5.4509 - val_accuracy: 0.0110\n",
      "Epoch 86/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1957 - accuracy: 0.0242 - lr: 0.00035 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1955 - accuracy: 0.0242 - val_loss: 5.4505 - val_accuracy: 0.0105\n",
      "Epoch 87/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1952 - accuracy: 0.0240 - lr: 0.00033 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1951 - accuracy: 0.0240 - val_loss: 5.4512 - val_accuracy: 0.0102\n",
      "Epoch 88/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1946 - accuracy: 0.0243 - lr: 0.00030 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.1946 - accuracy: 0.0243 - val_loss: 5.4518 - val_accuracy: 0.0103\n",
      "Epoch 89/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1936 - accuracy: 0.0245 - lr: 0.00028 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.1938 - accuracy: 0.0244 - val_loss: 5.4513 - val_accuracy: 0.0104\n",
      "Epoch 90/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1930 - accuracy: 0.0245 - lr: 0.00025 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.1932 - accuracy: 0.0245 - val_loss: 5.4516 - val_accuracy: 0.0106\n",
      "Epoch 91/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1923 - accuracy: 0.0245 - lr: 0.00023 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.1927 - accuracy: 0.0245 - val_loss: 5.4530 - val_accuracy: 0.0111\n",
      "Epoch 92/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1923 - accuracy: 0.0239 - lr: 0.00020 \n",
      "157/157 [==============================] - 5s 32ms/step - loss: 5.1923 - accuracy: 0.0239 - val_loss: 5.4553 - val_accuracy: 0.0109\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.1916 - accuracy: 0.0242 - lr: 0.00018 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.1916 - accuracy: 0.0242 - val_loss: 5.4514 - val_accuracy: 0.0105\n",
      "Epoch 94/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1911 - accuracy: 0.0239 - lr: 0.00015 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.1910 - accuracy: 0.0239 - val_loss: 5.4519 - val_accuracy: 0.0107\n",
      "Epoch 95/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1906 - accuracy: 0.0243 - lr: 0.00013 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1906 - accuracy: 0.0242 - val_loss: 5.4538 - val_accuracy: 0.0107\n",
      "Epoch 96/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1897 - accuracy: 0.0242 - lr: 0.00010 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1900 - accuracy: 0.0242 - val_loss: 5.4529 - val_accuracy: 0.0111\n",
      "Epoch 97/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1896 - accuracy: 0.0245 - lr: 0.00008 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1896 - accuracy: 0.0245 - val_loss: 5.4525 - val_accuracy: 0.0109\n",
      "Epoch 98/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1890 - accuracy: 0.0241 - lr: 0.00005 \n",
      "157/157 [==============================] - 5s 34ms/step - loss: 5.1891 - accuracy: 0.0241 - val_loss: 5.4526 - val_accuracy: 0.0108\n",
      "Epoch 99/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.1887 - accuracy: 0.0244 - lr: 0.00003 \n",
      "157/157 [==============================] - 6s 36ms/step - loss: 5.1886 - accuracy: 0.0244 - val_loss: 5.4526 - val_accuracy: 0.0106\n",
      "Epoch 100/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.1878 - accuracy: 0.0245 - lr: 0.00001 \n",
      "157/157 [==============================] - 5s 33ms/step - loss: 5.1880 - accuracy: 0.0245 - val_loss: 5.4526 - val_accuracy: 0.0111\n",
      "\n",
      "############### Training Completed #################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#region Model Configuration\n",
    "MODEL_CONFIG = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 512,\n",
    "    'input_size': 700,\n",
    "    'learning_rate': 5e-3,\n",
    "    'attack_traces': 5000,\n",
    "    'model_save_path': './Model/Source_Model(RandomMDS).h5'\n",
    "}\n",
    "#endregion\n",
    "\n",
    "#region Data Preparation\n",
    "# Load dataset with proper error handling\n",
    "\n",
    "(x_train, y_train, x_test, y_test, \n",
    "     p_train, p_test) = load_CW_Source(in_file='./DataSet/AES_RandomMDS/',sec=80000)\n",
    "\n",
    "\n",
    "# Preprocess targets\n",
    "y_train = y_train[:, 0]\n",
    "y_test = y_test[:, 0]\n",
    "\n",
    "# Shuffle training data\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "# Standardization and Normalization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train).astype('float32')\n",
    "x_test = scaler.transform(x_test).astype('float32')\n",
    "\n",
    "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = minmax_scaler.fit_transform(x_train)\n",
    "x_test = minmax_scaler.transform(x_test)\n",
    "#endregion\n",
    "\n",
    "\n",
    "#Model Initialization\n",
    "try:\n",
    "    model = cnn_classifier(\n",
    "        input_size=MODEL_CONFIG['input_size'],\n",
    "        learning_rate=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Model creation failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "#region Training Execution\n",
    "print(\"\\n############### Starting Training #################\\n\")\n",
    "try:\n",
    "    training_history = train_model(\n",
    "        x_train, y_train,\n",
    "        x_test, y_test,\n",
    "        model=model,\n",
    "        save_file_name=MODEL_CONFIG['model_save_path'],\n",
    "        epochs=MODEL_CONFIG['epochs'],\n",
    "        batch_size=MODEL_CONFIG['batch_size'],\n",
    "        max_lr=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n############### Training Completed #################\\n\")\n",
    "#endregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-krease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
