{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from utils.CLR import*\n",
    "from utils.LoadData import load_CW_Source\n",
    "from Model.CNN import cnn_classifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def train_model(X_profiling, Y_profiling, X_test, Y_test, model, save_file_name, epochs=150, batch_size=100,\n",
    "                max_lr=1e-3):\n",
    "\n",
    "    # Save model every epoch\n",
    "    save_model = ModelCheckpoint(\n",
    "                    filepath=save_file_name,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    save_best_only=True)\n",
    "\n",
    "    # Get the input layer shape\n",
    "    input_layer_shape = model.get_layer(index=0).input_shape[0]\n",
    "\n",
    "    # Sanity check\n",
    "    if input_layer_shape[1] != len(X_profiling[0]):\n",
    "        print(\"Error: model input shape %d instead of %d is not expected ...\" % (\n",
    "        input_layer_shape[1], len(X_profiling[0])))\n",
    "        sys.exit(-1)\n",
    "    Reshaped_X_profiling, Reshaped_X_test = X_profiling.reshape(\n",
    "        (X_profiling.shape[0], X_profiling.shape[1], 1)), X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # One Cycle Policy\n",
    "    lr_manager = OneCycleLR(max_lr=max_lr, end_percentage=0.2, scale_percentage=0.1, maximum_momentum=None,\n",
    "                            minimum_momentum=None, verbose=True)\n",
    "\n",
    "    callbacks = [save_model, lr_manager]\n",
    "\n",
    "    history = model.fit(x=Reshaped_X_profiling, y=to_categorical(Y_profiling, num_classes=256),\n",
    "                        validation_data=(Reshaped_X_test, to_categorical(Y_test, num_classes=256)),\n",
    "                        batch_size=batch_size, verbose=1, epochs=epochs, callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 1)]          0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 500, 4)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 500, 4)            16        \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 250, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               4352      \n",
      "=================================================================\n",
      "Total params: 20,664\n",
      "Trainable params: 20,656\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "\n",
      "############### Starting Training #################\n",
      "\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 5.5916 - accuracy: 0.0055 - lr: 0.00061 \n",
      "36/36 [==============================] - 1s 26ms/step - loss: 5.5916 - accuracy: 0.0055 - val_loss: 5.5595 - val_accuracy: 0.0020\n",
      "Epoch 2/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 5.4903 - accuracy: 0.0102 - lr: 0.00072 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 5.4889 - accuracy: 0.0103 - val_loss: 5.5310 - val_accuracy: 0.0025\n",
      "Epoch 3/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 5.3112 - accuracy: 0.0212 - lr: 0.00083 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 5.3063 - accuracy: 0.0214 - val_loss: 5.4411 - val_accuracy: 0.0100\n",
      "Epoch 4/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 4.9299 - accuracy: 0.0379 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 4.9161 - accuracy: 0.0384 - val_loss: 5.1901 - val_accuracy: 0.0375\n",
      "Epoch 5/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 4.3716 - accuracy: 0.0771 - lr: 0.00106 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 4.3632 - accuracy: 0.0781 - val_loss: 4.7719 - val_accuracy: 0.0710\n",
      "Epoch 6/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 3.7040 - accuracy: 0.1659 - lr: 0.00117 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.6914 - accuracy: 0.1678 - val_loss: 4.1810 - val_accuracy: 0.1275\n",
      "Epoch 7/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 2.8509 - accuracy: 0.3018 - lr: 0.00128 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.8492 - accuracy: 0.3021 - val_loss: 3.3545 - val_accuracy: 0.2660\n",
      "Epoch 8/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 2.0516 - accuracy: 0.4493 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.0396 - accuracy: 0.4526 - val_loss: 2.5060 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 1.4917 - accuracy: 0.5767 - lr: 0.00151 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.4883 - accuracy: 0.5769 - val_loss: 1.9506 - val_accuracy: 0.4975\n",
      "Epoch 10/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 1.1472 - accuracy: 0.6651 - lr: 0.00162 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.1429 - accuracy: 0.6659 - val_loss: 1.5289 - val_accuracy: 0.5835\n",
      "Epoch 11/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.9341 - accuracy: 0.7178 - lr: 0.00173 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.9329 - accuracy: 0.7176 - val_loss: 1.2380 - val_accuracy: 0.6315\n",
      "Epoch 12/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.7944 - accuracy: 0.7551 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.7923 - accuracy: 0.7553 - val_loss: 1.1019 - val_accuracy: 0.6645\n",
      "Epoch 13/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.7901 - lr: 0.00196 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.6760 - accuracy: 0.7902 - val_loss: 0.9698 - val_accuracy: 0.6965\n",
      "Epoch 14/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.5911 - accuracy: 0.8161 - lr: 0.00207 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.5922 - accuracy: 0.8147 - val_loss: 0.8471 - val_accuracy: 0.7280\n",
      "Epoch 15/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.5264 - accuracy: 0.8346 - lr: 0.00218 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.5258 - accuracy: 0.8347 - val_loss: 0.6949 - val_accuracy: 0.7795\n",
      "Epoch 16/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.4640 - accuracy: 0.8524 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.4666 - accuracy: 0.8513 - val_loss: 0.6399 - val_accuracy: 0.7835\n",
      "Epoch 17/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.4374 - accuracy: 0.8575 - lr: 0.00241 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.4370 - accuracy: 0.8581 - val_loss: 0.6015 - val_accuracy: 0.8095\n",
      "Epoch 18/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3848 - accuracy: 0.8737 - lr: 0.00252 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3851 - accuracy: 0.8736 - val_loss: 0.5446 - val_accuracy: 0.8170\n",
      "Epoch 19/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.8823 - lr: 0.00263 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3543 - accuracy: 0.8825 - val_loss: 0.5835 - val_accuracy: 0.8055\n",
      "Epoch 20/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3275 - accuracy: 0.8928 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3261 - accuracy: 0.8936 - val_loss: 0.4376 - val_accuracy: 0.8580\n",
      "Epoch 21/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8916 - lr: 0.00286 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3127 - accuracy: 0.8916 - val_loss: 0.5593 - val_accuracy: 0.8190\n",
      "Epoch 22/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.3089 - accuracy: 0.8962 - lr: 0.00297 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3127 - accuracy: 0.8946 - val_loss: 0.4482 - val_accuracy: 0.8470\n",
      "Epoch 23/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2996 - accuracy: 0.8974 - lr: 0.00308 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2992 - accuracy: 0.8975 - val_loss: 0.4369 - val_accuracy: 0.8555\n",
      "Epoch 24/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2990 - accuracy: 0.8964 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2958 - accuracy: 0.8974 - val_loss: 0.4825 - val_accuracy: 0.8490\n",
      "Epoch 25/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2656 - accuracy: 0.9085 - lr: 0.00331 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2646 - accuracy: 0.9098 - val_loss: 0.4262 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2516 - accuracy: 0.9118 - lr: 0.00342 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2506 - accuracy: 0.9122 - val_loss: 0.4584 - val_accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2475 - accuracy: 0.9139 - lr: 0.00353 \n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2449 - accuracy: 0.9144 - val_loss: 0.4555 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2474 - accuracy: 0.9142 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2485 - accuracy: 0.9138 - val_loss: 0.3679 - val_accuracy: 0.8885\n",
      "Epoch 29/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2622 - accuracy: 0.9089 - lr: 0.00376 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2613 - accuracy: 0.9093 - val_loss: 0.5135 - val_accuracy: 0.8375\n",
      "Epoch 30/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2533 - accuracy: 0.9112 - lr: 0.00387 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2525 - accuracy: 0.9117 - val_loss: 0.5934 - val_accuracy: 0.8205\n",
      "Epoch 31/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9210 - lr: 0.00398 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2260 - accuracy: 0.9211 - val_loss: 0.3728 - val_accuracy: 0.8820\n",
      "Epoch 32/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9181 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2406 - accuracy: 0.9176 - val_loss: 0.5402 - val_accuracy: 0.8435\n",
      "Epoch 33/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9154 - lr: 0.00421 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2457 - accuracy: 0.9155 - val_loss: 0.8314 - val_accuracy: 0.7720\n",
      "Epoch 34/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2228 - accuracy: 0.9223 - lr: 0.00432 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2230 - accuracy: 0.9225 - val_loss: 0.4886 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2153 - accuracy: 0.9245 - lr: 0.00443 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2165 - accuracy: 0.9238 - val_loss: 0.4132 - val_accuracy: 0.8635\n",
      "Epoch 36/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2286 - accuracy: 0.9191 - lr: 0.00455 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2287 - accuracy: 0.9192 - val_loss: 0.4785 - val_accuracy: 0.8555\n",
      "Epoch 37/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2691 - accuracy: 0.9084 - lr: 0.00466 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2711 - accuracy: 0.9071 - val_loss: 1.3045 - val_accuracy: 0.6990\n",
      "Epoch 38/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2646 - accuracy: 0.9096 - lr: 0.00477 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2640 - accuracy: 0.9103 - val_loss: 2.7006 - val_accuracy: 0.4970\n",
      "Epoch 39/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.2146 - accuracy: 0.9248 - lr: 0.00488 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2138 - accuracy: 0.9244 - val_loss: 0.5340 - val_accuracy: 0.8465\n",
      "Epoch 40/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1887 - accuracy: 0.9338 - lr: 0.00500 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1877 - accuracy: 0.9342 - val_loss: 0.7486 - val_accuracy: 0.7965\n",
      "Epoch 41/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.1916 - accuracy: 0.9339 - lr: 0.00489 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1920 - accuracy: 0.9341 - val_loss: 0.4386 - val_accuracy: 0.8685\n",
      "Epoch 42/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.2141 - accuracy: 0.9267 - lr: 0.00478 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2128 - accuracy: 0.9273 - val_loss: 2.0268 - val_accuracy: 0.5685\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9381 - lr: 0.00467 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.1762 - accuracy: 0.9381 - val_loss: 0.4631 - val_accuracy: 0.8590\n",
      "Epoch 44/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1581 - accuracy: 0.9435 - lr: 0.00455 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1568 - accuracy: 0.9440 - val_loss: 0.3549 - val_accuracy: 0.8875\n",
      "Epoch 45/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1268 - accuracy: 0.9578 - lr: 0.00444 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1271 - accuracy: 0.9578 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 46/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1242 - accuracy: 0.9568 - lr: 0.00433 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1241 - accuracy: 0.9567 - val_loss: 0.5091 - val_accuracy: 0.8575\n",
      "Epoch 47/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9602 - lr: 0.00422 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1135 - accuracy: 0.9601 - val_loss: 0.3546 - val_accuracy: 0.8905\n",
      "Epoch 48/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9603 - lr: 0.00410 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1147 - accuracy: 0.9603 - val_loss: 0.3826 - val_accuracy: 0.8770\n",
      "Epoch 49/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0907 - accuracy: 0.9685 - lr: 0.00399 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0904 - accuracy: 0.9687 - val_loss: 0.5441 - val_accuracy: 0.8440\n",
      "Epoch 50/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0899 - accuracy: 0.9689 - lr: 0.00388 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0906 - accuracy: 0.9686 - val_loss: 0.7843 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0921 - accuracy: 0.9673 - lr: 0.00377 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.6592 - val_accuracy: 0.8245\n",
      "Epoch 52/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0851 - accuracy: 0.9708 - lr: 0.00365 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.4338 - val_accuracy: 0.8715\n",
      "Epoch 53/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0897 - accuracy: 0.9695 - lr: 0.00354 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0889 - accuracy: 0.9698 - val_loss: 0.3542 - val_accuracy: 0.8985\n",
      "Epoch 54/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0754 - accuracy: 0.9741 - lr: 0.00343 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0760 - accuracy: 0.9741 - val_loss: 0.2997 - val_accuracy: 0.9050\n",
      "Epoch 55/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0534 - accuracy: 0.9832 - lr: 0.00332 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.3480 - val_accuracy: 0.8975\n",
      "Epoch 56/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0587 - accuracy: 0.9809 - lr: 0.00320 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 0.3150 - val_accuracy: 0.9040\n",
      "Epoch 57/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0514 - accuracy: 0.9836 - lr: 0.00309 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.3304 - val_accuracy: 0.9025\n",
      "Epoch 58/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0476 - accuracy: 0.9862 - lr: 0.00298 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0474 - accuracy: 0.9863 - val_loss: 0.3003 - val_accuracy: 0.9055\n",
      "Epoch 59/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0438 - accuracy: 0.9862 - lr: 0.00287 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.3168 - val_accuracy: 0.9050\n",
      "Epoch 60/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0468 - accuracy: 0.9849 - lr: 0.00275 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.3524 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0388 - accuracy: 0.9902 - lr: 0.00264 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.3238 - val_accuracy: 0.8990\n",
      "Epoch 62/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0329 - accuracy: 0.9910 - lr: 0.00253 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.3061 - val_accuracy: 0.9120\n",
      "Epoch 63/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0243 - accuracy: 0.9952 - lr: 0.00242 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 0.3267 - val_accuracy: 0.9040\n",
      "Epoch 64/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9942 - lr: 0.00230 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 0.2898 - val_accuracy: 0.9125\n",
      "Epoch 65/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0191 - accuracy: 0.9970 - lr: 0.00219 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.3386 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9987 - lr: 0.00208 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0149 - accuracy: 0.9987 - val_loss: 0.3041 - val_accuracy: 0.9070\n",
      "Epoch 67/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0123 - accuracy: 0.9993 - lr: 0.00197 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0124 - accuracy: 0.9993 - val_loss: 0.2905 - val_accuracy: 0.9110\n",
      "Epoch 68/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0107 - accuracy: 0.9997 - lr: 0.00185 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 0.2886 - val_accuracy: 0.9110\n",
      "Epoch 69/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0095 - accuracy: 0.9996 - lr: 0.00174 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 0.9996 - val_loss: 0.2955 - val_accuracy: 0.9135\n",
      "Epoch 70/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0093 - accuracy: 0.9995 - lr: 0.00163 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0094 - accuracy: 0.9996 - val_loss: 0.3011 - val_accuracy: 0.9130\n",
      "Epoch 71/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 0.9997 - lr: 0.00152 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9997 - val_loss: 0.2998 - val_accuracy: 0.9120\n",
      "Epoch 72/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0080 - accuracy: 0.9999 - lr: 0.00140 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9999 - val_loss: 0.3099 - val_accuracy: 0.9070\n",
      "Epoch 73/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0075 - accuracy: 0.9999 - lr: 0.00129 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9999 - val_loss: 0.3021 - val_accuracy: 0.9090\n",
      "Epoch 74/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0069 - accuracy: 0.9999 - lr: 0.00118 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 0.9999 - val_loss: 0.3001 - val_accuracy: 0.9075\n",
      "Epoch 75/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - lr: 0.00107 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9115\n",
      "Epoch 76/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000 - lr: 0.00095 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9125\n",
      "Epoch 77/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000 - lr: 0.00084 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9115\n",
      "Epoch 78/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000 - lr: 0.00073 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9135\n",
      "Epoch 79/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000 - lr: 0.00062 \n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9145\n",
      "Epoch 80/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - lr: 0.00050 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9170\n",
      "Epoch 81/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - lr: 0.00048 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9165\n",
      "Epoch 82/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - lr: 0.00045 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9160\n",
      "Epoch 83/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - lr: 0.00043 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9170\n",
      "Epoch 84/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - lr: 0.00040 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9170\n",
      "Epoch 85/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - lr: 0.00038 \n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9170\n",
      "Epoch 86/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - lr: 0.00035 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9155\n",
      "Epoch 87/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - lr: 0.00033 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9150\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - lr: 0.00030 \n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9150\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000 - lr: 0.00028 \n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9165\n",
      "Epoch 90/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - lr: 0.00025 \n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9165\n",
      "Epoch 91/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - lr: 0.00023 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9170\n",
      "Epoch 92/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - lr: 0.00020 \n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9165\n",
      "Epoch 93/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - lr: 0.00018 \n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9160\n",
      "Epoch 94/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - lr: 0.00015 \n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9165\n",
      "Epoch 95/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - lr: 0.00013 \n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9170\n",
      "Epoch 96/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - lr: 0.00010 \n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9170\n",
      "Epoch 97/100\n",
      "34/36 [===========================>..] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - lr: 0.00008 \n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9165\n",
      "Epoch 98/100\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - lr: 0.00006 \n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9165\n",
      "Epoch 99/100\n",
      "33/36 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - lr: 0.00003 \n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9165\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - lr: 0.00001 \n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9165\n",
      "\n",
      "############### Training Completed #################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#region Model Configuration\n",
    "MODEL_CONFIG = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 512,\n",
    "    'input_size': 500,\n",
    "    'learning_rate': 5e-3,\n",
    "    'attack_traces': 5000,\n",
    "    'model_save_path': './Model/TK1=0xdf.h5'\n",
    "}\n",
    "#endregion\n",
    "\n",
    "#region Data Preparation\n",
    "# Load dataset with proper error handling\n",
    "\n",
    "(x_train, y_train, x_test, y_test, \n",
    "     p_train, p_test) = load_CW_Source(in_file='./DataSet/TK1=0xdf,TK2=0xab/',sec=18000)\n",
    "\n",
    "\n",
    "# Preprocess targets\n",
    "y_train = y_train[:]\n",
    "y_test = y_test[:]\n",
    "\n",
    "# Shuffle training data\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "# Standardization and Normalization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train).astype('float32')\n",
    "x_test = scaler.transform(x_test).astype('float32')\n",
    "\n",
    "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = minmax_scaler.fit_transform(x_train)\n",
    "x_test = minmax_scaler.transform(x_test)\n",
    "#endregion\n",
    "\n",
    "\n",
    "#Model Initialization\n",
    "try:\n",
    "    model = cnn_classifier(\n",
    "        input_size=MODEL_CONFIG['input_size'],\n",
    "        learning_rate=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Model creation failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "#region Training Execution\n",
    "print(\"\\n############### Starting Training #################\\n\")\n",
    "try:\n",
    "    training_history = train_model(\n",
    "        x_train, y_train,\n",
    "        x_test, y_test,\n",
    "        model=model,\n",
    "        save_file_name=MODEL_CONFIG['model_save_path'],\n",
    "        epochs=MODEL_CONFIG['epochs'],\n",
    "        batch_size=MODEL_CONFIG['batch_size'],\n",
    "        max_lr=MODEL_CONFIG['learning_rate']\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n############### Training Completed #################\\n\")\n",
    "#endregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-krease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
